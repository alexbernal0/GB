{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b79d6d97",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "show me the first few rows of each dataset in dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f173f765",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "\n",
    "\n",
    "I've loaded both datasets and displayed the first few rows of each. Here's a summary of what we can see:\n",
    "\n",
    "1. US Retail Sales MoM dataset:\n",
    "{outputs_dict['d4d5c67f']}\n",
    "\n",
    "2. ADP Small Establishment Private Employment MoM dataset:\n",
    "{outputs_dict['4bb88425']}\n",
    "\n",
    "Both datasets contain monthly data with a \"Period\" column representing the date and a corresponding value column. The US Retail Sales data is presented as a percentage change, while the ADP Employment data shows the change in the number of employees.\n",
    "\n",
    "The US Retail Sales data shows month-over-month percentage changes, with both positive and negative values. The ADP Employment data shows the monthly change in the number of employees in small establishments, with values in thousands (e.g., -7000 represents a decrease of 7,000 employees).\n",
    "\n",
    "Both datasets are in reverse chronological order, with the most recent data point at the top. The US Retail Sales data starts from June 2024, while the ADP Employment data starts from July 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49445b69",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "ok do a left join of the ADP data set on the US retail sale dataset, and show me the dataframe after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dc93b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a left join of the ADP dataset on the US Retail Sales dataset\n",
    "\n",
    "# Merge the datasets on the 'Period' column\n",
    "merged_df = pd.merge(df_retail_sales, df_adp_employment, on='Period', how='left')\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698b9842",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "The left join of the ADP dataset on the US Retail Sales dataset has been completed. Here are the first few rows of the resulting dataframe:\n",
    "\n",
    "{outputs_dict['3a45a0da']}\n",
    "\n",
    "The merged dataframe now contains the \"Period\", \"US Retail Sales MoM (Percent)\", and \"ADP Small Establishment Private Employment MoM\" columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef6040",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "I uploaded the following files: 3_USISMBizActInd.csv left join this dataset on the one above and show me the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new dataset\n",
    "\n",
    "# Load the ISM Business Activity Index dataset\n",
    "df_ism_biz_act = pd.read_csv('3_USISMBizActInd.csv')\n",
    "\n",
    "# Perform a left join of the ISM dataset on the previously merged dataset\n",
    "final_merged_df = pd.merge(merged_df, df_ism_biz_act, on='Period', how='left')\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(final_merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef5cd04",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "The left join of the ISM Business Activity Index dataset on the previously merged dataset has been completed. Here are the first few rows of the resulting dataframe:\n",
    "\n",
    "{outputs_dict['72227519']}\n",
    "\n",
    "The final merged dataframe now contains the following columns:\n",
    "- Period\n",
    "- US Retail Sales MoM (Percent)\n",
    "- ADP Small Establishment Private Employment MoM\n",
    "- US ISM Services Business Activity Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80998e87",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "I uploaded the following files: 4_BankLoanPrimeRate.csv left join this dataset on the dataframe above and show me after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb9b12f",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "Certainly! I'll load the Bank Loan Prime Rate dataset, perform a left join with the previously merged dataframe, and show you the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd386081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Bank Loan Prime Rate dataset\n",
    "df_bank_loan_rate = pd.read_csv('4_BankLoanPrimeRate.csv')\n",
    "\n",
    "# Perform a left join of the Bank Loan Prime Rate dataset on the previously merged dataframe\n",
    "final_merged_df = pd.merge(final_merged_df, df_bank_loan_rate, on='Period', how='left')\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(final_merged_df.head())\n",
    "\n",
    "# Display info about the dataframe\n",
    "print(\"\\nDataframe Info:\")\n",
    "print(final_merged_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec5bcc6",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "\n",
    "\n",
    "The left join of the Bank Loan Prime Rate dataset on the previously merged dataframe has been completed. Here are the first few rows of the resulting dataframe:\n",
    "\n",
    "{outputs_dict['0a5c5171']}\n",
    "\n",
    "Additionally, here's some information about the final merged dataframe:\n",
    "\n",
    "{outputs_dict['1416f143']}\n",
    "\n",
    "The final merged dataframe now contains the following columns:\n",
    "1. Period (date)\n",
    "2. US Retail Sales MoM (Percent)\n",
    "3. ADP Small Establishment Private Employment MoM\n",
    "4. US ISM Services Business Activity Index\n",
    "5. Bank Prime Loan Rate (Percent)\n",
    "\n",
    "All columns have 126 non-null entries, which means there are no missing values in the dataset. The 'Period' column is of type object (likely string representations of dates), while all other columns are of type float64, representing numerical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2839a379",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "I uploaded the following files: 5_2s10sSpread.csv left join this dataset on the dataframe above and show me after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8081e62",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "Certainly! I'll load the 5_2s10sSpread.csv file, perform a left join with our existing dataframe, and show you the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6d0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 2s10s Spread dataset\n",
    "df_2s10s_spread = pd.read_csv('5_2s10sSpread.csv')\n",
    "\n",
    "# Perform a left join of the 2s10s Spread dataset on the previously merged dataframe\n",
    "final_merged_df = pd.merge(final_merged_df, df_2s10s_spread, on='Period', how='left')\n",
    "\n",
    "# Display the first few rows of the resulting dataframe\n",
    "print(final_merged_df.head())\n",
    "\n",
    "# Display info about the dataframe\n",
    "print(\"\\nDataframe Info:\")\n",
    "print(final_merged_df.info())\n",
    "\n",
    "# Display a summary of the dataframe\n",
    "print(\"\\nDataframe Summary:\")\n",
    "print(final_merged_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd02b4bb",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "\n",
    "\n",
    "The left join of the 2s10s Spread dataset on the previously merged dataframe has been completed. Here are the first few rows of the resulting dataframe:\n",
    "\n",
    "{outputs_dict['caaa75a3']}\n",
    "\n",
    "Here's some information about the final merged dataframe:\n",
    "\n",
    "{outputs_dict['65023444']}\n",
    "\n",
    "And a summary of the numerical columns in the dataframe:\n",
    "\n",
    "{outputs_dict['25f66a7c']}\n",
    "\n",
    "Key observations:\n",
    "1. The final merged dataframe now contains 6 columns, including the new \"10-2 Year Treasury Yield Spread (Percent)\" column.\n",
    "2. All columns except the new one have 126 non-null entries. The \"10-2 Year Treasury Yield Spread (Percent)\" column has 88 non-null entries, indicating some missing values.\n",
    "3. The 'Period' column remains as object type (likely string representations of dates), while all other columns are float64 type.\n",
    "4. The summary statistics show the range and distribution of values for each numerical column:\n",
    "   - US Retail Sales MoM ranges from -13.06% to 17.59%, with a mean of 0.41%.\n",
    "   - ADP Small Establishment Private Employment MoM ranges from -2,672,000 to 472,000, with a mean of 57,992.\n",
    "   - US ISM Services Business Activity Index ranges from 26.0 to 74.6, with a mean of 59.12.\n",
    "   - Bank Prime Loan Rate ranges from 3.25% to 8.5%, with a mean of 4.61%.\n",
    "   - 10-2 Year Treasury Yield Spread ranges from -1.06% to 2.33%, with a mean of 0.63%.\n",
    "\n",
    "The presence of missing values in the 10-2 Year Treasury Yield Spread column and the varying ranges of the different metrics suggest that further data cleaning and normalization might be necessary for certain types of analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b218f84e",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "can you try that again but if there is no date on the 2s10s dataframe, can you just use the nearest to date so the end result has no null values after the left join please"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d9fb4a",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "No Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4492b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 2s10s Spread dataset\n",
    "df_2s10s_spread = pd.read_csv('5_2s10sSpread.csv')\n",
    "\n",
    "# Convert the 'Period' columns to datetime for merging\n",
    "final_merged_df['Period'] = pd.to_datetime(final_merged_df['Period'])\n",
    "df_2s10s_spread['Period'] = pd.to_datetime(df_2s10s_spread['Period'])\n",
    "\n",
    "# Perform a left join with the nearest date matching\n",
    "final_merged_df = pd.merge_asof(final_merged_df.sort_values('Period'), df_2s10s_spread.sort_values('Period'), on='Period', direction='nearest')\n",
    "\n",
    "# Display the first few rows of the resulting dataframe\n",
    "print(final_merged_df.head())\n",
    "\n",
    "# Display info about the dataframe\n",
    "print(\"\\nDataframe Info:\")\n",
    "print(final_merged_df.info())\n",
    "\n",
    "# Display a summary of the dataframe\n",
    "print(\"\\nDataframe Summary:\")\n",
    "print(final_merged_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ce7841",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "The left join of the 2s10s Spread dataset on the previously merged dataframe has been completed using the nearest date matching. Here are the first few rows of the resulting dataframe:\n",
    "\n",
    "{outputs_dict['362f2983']}\n",
    "\n",
    "Here's some information about the final merged dataframe:\n",
    "\n",
    "{outputs_dict['62b81982']}\n",
    "\n",
    "And a summary of the numerical columns in the dataframe:\n",
    "\n",
    "{outputs_dict['fcd39eeb']}\n",
    "\n",
    "Key observations:\n",
    "1. The final merged dataframe now contains 7 columns, including the new \"10-2 Year Treasury Yield Spread (Percent)\" column.\n",
    "2. The 'Period' column is now of type datetime64[ns], while all other columns are float64 type.\n",
    "3. The summary statistics show the range and distribution of values for each numerical column, similar to the previous analysis.\n",
    "4. The \"10-2 Year Treasury Yield Spread (Percent)\" column has been successfully filled with the nearest available values, reducing the number of null values.\n",
    "\n",
    "The presence of two columns for the 10-2 Year Treasury Yield Spread indicates that the merge operation might have created duplicate columns. We can clean this up by keeping only one of these columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96264568",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "I uploaded the following files: 6_CCCUSHY_Spread.csv perfect thank you, do the same thing with this dataset, left join on the one above and if the dates dont match use the closest to date so the output has no null values after the join, show me the dataframe after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2313149f",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "No Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CCC US High Yield Spread dataset\n",
    "df_ccc_hy_spread = pd.read_csv('6_CCCUSHY_Spread.csv')\n",
    "\n",
    "# Convert the 'Period' columns to datetime for merging\n",
    "final_merged_df['Period'] = pd.to_datetime(final_merged_df['Period'])\n",
    "df_ccc_hy_spread['Period'] = pd.to_datetime(df_ccc_hy_spread['Period'])\n",
    "\n",
    "# Perform a left join with the nearest date matching\n",
    "final_merged_df = pd.merge_asof(final_merged_df.sort_values('Period'), df_ccc_hy_spread.sort_values('Period'), on='Period', direction='nearest')\n",
    "\n",
    "# Display the first few rows of the resulting dataframe\n",
    "print(final_merged_df.head())\n",
    "\n",
    "# Display info about the dataframe\n",
    "print(\"\\nDataframe Info:\")\n",
    "print(final_merged_df.info())\n",
    "\n",
    "# Display a summary of the dataframe\n",
    "print(\"\\nDataframe Summary:\")\n",
    "print(final_merged_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c198b0df",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "The left join of the CCC US High Yield Spread dataset on the previously merged dataframe has been completed using the nearest date matching. Here are the first few rows of the resulting dataframe:\n",
    "\n",
    "{outputs_dict['feb87074']}\n",
    "\n",
    "Here's some information about the final merged dataframe:\n",
    "\n",
    "{outputs_dict['172b2596']}\n",
    "\n",
    "And a summary of the numerical columns in the dataframe:\n",
    "\n",
    "{outputs_dict['21e5cb27']}\n",
    "\n",
    "Key observations:\n",
    "1. The final merged dataframe now contains 8 columns, including the new \"US High Yield CCC or Below Option-Adjusted Spread (Percent)\" column.\n",
    "2. The 'Period' column is of type datetime64[ns], while all other columns are float64 type.\n",
    "3. The summary statistics show the range and distribution of values for each numerical column, similar to the previous analysis.\n",
    "4. The \"US High Yield CCC or Below Option-Adjusted Spread (Percent)\" column has been successfully filled with the nearest available values, reducing the number of null values.\n",
    "\n",
    "The presence of two columns for the 10-2 Year Treasury Yield Spread indicates that the merge operation might have created duplicate columns. We can clean this up by keeping only one of these columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791b79a",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "drop the 10-2 Year Treasury Yield Spread (Percent)_x column and show me the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b3581a",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "Certainly! I'll drop the duplicate column and show you the updated dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicate column\n",
    "final_merged_df = final_merged_df.drop(columns=['10-2 Year Treasury Yield Spread (Percent)_x'])\n",
    "\n",
    "# Rename the remaining column to remove the '_y' suffix\n",
    "final_merged_df = final_merged_df.rename(columns={'10-2 Year Treasury Yield Spread (Percent)_y': '10-2 Year Treasury Yield Spread (Percent)'})\n",
    "\n",
    "# Display the first few rows of the resulting dataframe\n",
    "print(final_merged_df.head())\n",
    "\n",
    "# Display info about the dataframe\n",
    "print(\"\\nDataframe Info:\")\n",
    "print(final_merged_df.info())\n",
    "\n",
    "# Display a summary of the dataframe\n",
    "print(\"\\nDataframe Summary:\")\n",
    "print(final_merged_df.describe())\n",
    "\n",
    "# Display the column names\n",
    "print(\"\\nColumn Names:\")\n",
    "print(final_merged_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d305c3a",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "\n",
    "\n",
    "I've dropped the duplicate column and renamed the remaining one. Here's the updated dataframe:\n",
    "\n",
    "{outputs_dict['c2b0f5a8']}\n",
    "\n",
    "Here's the updated information about the final merged dataframe:\n",
    "\n",
    "{outputs_dict['4079047f']}\n",
    "\n",
    "A summary of the numerical columns in the dataframe:\n",
    "\n",
    "{outputs_dict['b416eac8']}\n",
    "\n",
    "And here are the column names of the final dataframe:\n",
    "\n",
    "{outputs_dict['4a021fe7']}\n",
    "\n",
    "Key observations:\n",
    "1. The dataframe now contains 7 columns, with the duplicate \"10-2 Year Treasury Yield Spread (Percent)\" column removed.\n",
    "2. All columns have 126 non-null entries, indicating there are no missing values in the dataset.\n",
    "3. The 'Period' column is of type datetime64[ns], while all other columns are float64 type.\n",
    "4. The summary statistics show the range and distribution of values for each numerical column:\n",
    "   - US Retail Sales MoM ranges from -13.06% to 17.59%, with a mean of 0.41%.\n",
    "   - ADP Small Establishment Private Employment MoM ranges from -2,672,000 to 472,000, with a mean of 57,992.\n",
    "   - US ISM Services Business Activity Index ranges from 26.0 to 74.6, with a mean of 59.12.\n",
    "   - Bank Prime Loan Rate ranges from 3.25% to 8.5%, with a mean of 4.61%.\n",
    "   - 10-2 Year Treasury Yield Spread ranges from -1.06% to 2.33%, with a mean of 0.64%.\n",
    "   - US High Yield CCC or Below Option-Adjusted Spread ranges from 5.83% to 20.93%, with a mean of 9.86%.\n",
    "\n",
    "The dataframe now contains a comprehensive set of economic indicators without any missing values, ready for further analysis or visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead13d92",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "I uploaded the following files: 7_PercBanksWilling2Loan.csv left join this dataset on the one above, and if the dates dont match exactly please use the nearest date so the result does not have any null values after the join. show me the dataset after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04d3dd4",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "Certainly! I'll perform the left join with the new dataset using the nearest date matching to avoid null values. Here's the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3439dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Percentage of Banks Willing to Loan dataset\n",
    "df_banks_willing = pd.read_csv('7_PercBanksWilling2Loan.csv')\n",
    "\n",
    "# Convert the 'Period' columns to datetime for merging\n",
    "df_banks_willing['Period'] = pd.to_datetime(df_banks_willing['Period'])\n",
    "\n",
    "# Perform a left join with the nearest date matching\n",
    "final_merged_df = pd.merge_asof(final_merged_df.sort_values('Period'), \n",
    "                                df_banks_willing.sort_values('Period'), \n",
    "                                on='Period', \n",
    "                                direction='nearest')\n",
    "\n",
    "# Display the first few rows of the resulting dataframe\n",
    "print(final_merged_df.head())\n",
    "\n",
    "# Display info about the dataframe\n",
    "print(\"\\nDataframe Info:\")\n",
    "print(final_merged_df.info())\n",
    "\n",
    "# Display a summary of the dataframe\n",
    "print(\"\\nDataframe Summary:\")\n",
    "print(final_merged_df.describe())\n",
    "\n",
    "# Display the column names\n",
    "print(\"\\nColumn Names:\")\n",
    "print(final_merged_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5e09a6",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "\n",
    "\n",
    "I've performed the left join with the Percentage of Banks Willing to Loan dataset using the nearest date matching. Here's the updated dataframe:\n",
    "\n",
    "{outputs_dict['14f3ccd8']}\n",
    "\n",
    "Here's the updated information about the final merged dataframe:\n",
    "\n",
    "{outputs_dict['1b7aca12']}\n",
    "\n",
    "A summary of the numerical columns in the dataframe:\n",
    "\n",
    "{outputs_dict['8068ad74']}\n",
    "\n",
    "And here are the column names of the final dataframe:\n",
    "\n",
    "{outputs_dict['9248c570']}\n",
    "\n",
    "Key observations:\n",
    "1. The dataframe now contains 8 columns, with the new column \"US Net Percentage of Banks Reporting Increased Willingness to Make Consumer Installment Loans (Percent)\" added.\n",
    "2. All columns have 126 non-null entries, indicating there are no missing values in the dataset.\n",
    "3. The 'Period' column is of type datetime64[ns], while all other columns are float64 type.\n",
    "4. The summary statistics show the range and distribution of values for each numerical column:\n",
    "   - US Retail Sales MoM ranges from -13.06% to 17.59%, with a mean of 0.41%.\n",
    "   - ADP Small Establishment Private Employment MoM ranges from -2,672,000 to 472,000, with a mean of 57,992.\n",
    "   - US ISM Services Business Activity Index ranges from 26.0 to 74.6, with a mean of 59.12.\n",
    "   - Bank Prime Loan Rate ranges from 3.25% to 8.5%, with a mean of 4.61%.\n",
    "   - 10-2 Year Treasury Yield Spread ranges from -1.06% to 2.33%, with a mean of 0.64%.\n",
    "   - US High Yield CCC or Below Option-Adjusted Spread ranges from 5.83% to 20.93%, with a mean of 9.86%.\n",
    "   - US Net Percentage of Banks Reporting Increased Willingness to Make Consumer Installment Loans ranges from -41.0% to 24.1%, with a mean of 4.28%.\n",
    "\n",
    "The dataframe now contains a comprehensive set of economic indicators without any missing values, including information on banks' willingness to make consumer installment loans. This dataset is ready for further analysis or visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c851fe82",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "I uploaded the following files: 8_imputed_USLEADINDEX_with_curvature.csv left join this dataset on the one above, and if the dates dont match exactly please use the nearest date so the result does not have any null values after the join. show me the dataset after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa5d459",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "Certainly! I'll perform the left join with the imputed US Leading Index dataset using the nearest date matching. Here's the code to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the imputed US Leading Index dataset\n",
    "df_us_lead_index = pd.read_csv('8_imputed_USLEADINDEX_with_curvature.csv')\n",
    "\n",
    "# Convert the 'Period' columns to datetime for merging\n",
    "df_us_lead_index['Period'] = pd.to_datetime(df_us_lead_index['Period'])\n",
    "\n",
    "# Perform a left join with the nearest date matching\n",
    "final_merged_df = pd.merge_asof(final_merged_df.sort_values('Period'), \n",
    "                                df_us_lead_index.sort_values('Period'), \n",
    "                                on='Period', \n",
    "                                direction='nearest')\n",
    "\n",
    "# Display the first few rows of the resulting dataframe\n",
    "print(final_merged_df.head())\n",
    "\n",
    "# Display info about the dataframe\n",
    "print(\"\\nDataframe Info:\")\n",
    "print(final_merged_df.info())\n",
    "\n",
    "# Display a summary of the dataframe\n",
    "print(\"\\nDataframe Summary:\")\n",
    "print(final_merged_df.describe())\n",
    "\n",
    "# Display the column names\n",
    "print(\"\\nColumn Names:\")\n",
    "print(final_merged_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca212047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the imputed US Leading Index dataset\n",
    "df_us_lead_index = pd.read_csv('8_imputed_USLEADINDEX_with_curvature.csv')\n",
    "\n",
    "# Check the column names to identify the issue\n",
    "print(df_us_lead_index.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c17437",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "\n",
    "\n",
    "I apologize for the error. It seems the column name in the new dataset is 'Date' instead of 'Period'. Let's adjust our code accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92d03d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the imputed US Leading Index dataset\n",
    "df_us_lead_index = pd.read_csv('8_imputed_USLEADINDEX_with_curvature.csv')\n",
    "\n",
    "# Rename 'Date' column to 'Period' for consistency\n",
    "df_us_lead_index = df_us_lead_index.rename(columns={'Date': 'Period'})\n",
    "\n",
    "# Convert the 'Period' columns to datetime for merging\n",
    "df_us_lead_index['Period'] = pd.to_datetime(df_us_lead_index['Period'])\n",
    "final_merged_df['Period'] = pd.to_datetime(final_merged_df['Period'])\n",
    "\n",
    "# Perform a left join with the nearest date matching\n",
    "final_merged_df = pd.merge_asof(final_merged_df.sort_values('Period'), \n",
    "                                df_us_lead_index.sort_values('Period'), \n",
    "                                on='Period', \n",
    "                                direction='nearest')\n",
    "\n",
    "# Display the first few rows of the resulting dataframe\n",
    "print(final_merged_df.head())\n",
    "\n",
    "# Display info about the dataframe\n",
    "print(\"\\nDataframe Info:\")\n",
    "print(final_merged_df.info())\n",
    "\n",
    "# Display a summary of the dataframe\n",
    "print(\"\\nDataframe Summary:\")\n",
    "print(final_merged_df.describe())\n",
    "\n",
    "# Display the column names\n",
    "print(\"\\nColumn Names:\")\n",
    "print(final_merged_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53195039",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "I've performed the left join with the imputed US Leading Index dataset using the nearest date matching. Here's the updated dataframe:\n",
    "\n",
    "{outputs_dict['da316702']}\n",
    "\n",
    "Here's the updated information about the final merged dataframe:\n",
    "\n",
    "{outputs_dict['1f26c30e']}\n",
    "\n",
    "A summary of the numerical columns in the dataframe:\n",
    "\n",
    "{outputs_dict['13f89e6c']}\n",
    "\n",
    "And here are the column names of the final dataframe:\n",
    "\n",
    "{outputs_dict['755b630e']}\n",
    "\n",
    "Key observations:\n",
    "1. The dataframe now contains 11 columns, with the new columns \"BCI\", \"BCIp\", and \"BCIg\" added.\n",
    "2. All columns have 126 non-null entries, indicating there are no missing values in the dataset.\n",
    "3. The 'Period' column is of type datetime64[ns], while all other columns are float64 type.\n",
    "4. The summary statistics show the range and distribution of values for each numerical column:\n",
    "   - US Retail Sales MoM ranges from -13.06% to 17.59%, with a mean of 0.41%.\n",
    "   - ADP Small Establishment Private Employment MoM ranges from -2,672,000 to 472,000, with a mean of 57,992.\n",
    "   - US ISM Services Business Activity Index ranges from 26.0 to 74.6, with a mean of 59.12.\n",
    "   - Bank Prime Loan Rate ranges from 3.25% to 8.5%, with a mean of 4.61%.\n",
    "   - 10-2 Year Treasury Yield Spread ranges from -1.06% to 2.33%, with a mean of 0.64%.\n",
    "   - US High Yield CCC or Below Option-Adjusted Spread ranges from 5.83% to 20.93%, with a mean of 9.86%.\n",
    "   - US Net Percentage of Banks Reporting Increased Willingness to Make Consumer Installment Loans ranges from -41.0% to 24.1%, with a mean of 4.28%.\n",
    "   - BCI ranges from 163.264 to 283.264, with a mean of 223.45.\n",
    "   - BCIp ranges from -177.08 to 100.0, with a mean of 65.50.\n",
    "   - BCIg ranges from -18.64 to 19.94, with a mean of 13.14.\n",
    "\n",
    "The dataframe now contains a comprehensive set of economic indicators without any missing values, including information on the US Leading Index. This dataset is ready for further analysis or visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9562de18",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "awesome now give me the link to export this dataset as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64fd1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final merged dataframe to a CSV file\n",
    "final_merged_df.to_csv('final_merged_dataset.csv', index=False)\n",
    "print('CSV file saved as final_merged_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35d131e",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "The final merged dataset has been saved as a CSV file. You can download it using the following link:\n",
    "\n",
    "[Download final_merged_dataset.csv](https://julius.ai/files?filename=final_merged_dataset.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb75efb",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "I uploaded the following files: GB2_shifted_data.csv, 8_AllTrainingDataGB1.csv import both of these and show me the first 10 rows of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95853705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GB2 shifted data dataset\n",
    "df_gb2_shifted = pd.read_csv('GB2_shifted_data.csv')\n",
    "\n",
    "# Load the All Training Data GB1 dataset\n",
    "df_all_training_gb1 = pd.read_csv('8_AllTrainingDataGB1.csv')\n",
    "\n",
    "# Display the first 10 rows of each dataset\n",
    "print('First 10 rows of GB2_shifted_data.csv:')\n",
    "print(df_gb2_shifted.head(10))\n",
    "\n",
    "print('\\nFirst 10 rows of 8_AllTrainingDataGB1.csv:')\n",
    "print(df_all_training_gb1.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9283b2",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "\n",
    "\n",
    "I've imported both datasets and here are the first 10 rows of each:\n",
    "\n",
    "First 10 rows of GB2_shifted_data.csv:\n",
    "\n",
    "{outputs_dict['b46ab8c0']}\n",
    "\n",
    "First 10 rows of 8_AllTrainingDataGB1.csv:\n",
    "\n",
    "{outputs_dict['0840db52']}\n",
    "\n",
    "Key observations:\n",
    "\n",
    "1. GB2_shifted_data.csv:\n",
    "   - Contains 6 columns: DATE, BUSLOANS, 3m, 6m, 9m, 12m\n",
    "   - DATE column starts from 2014-01-01\n",
    "   - BUSLOANS column seems to represent some kind of loan values\n",
    "   - The 3m, 6m, 9m, and 12m columns appear to be percentage values, possibly representing different time horizons\n",
    "\n",
    "2. 8_AllTrainingDataGB1.csv:\n",
    "   - Contains 11 columns with various economic indicators\n",
    "   - Period column starts from 2014-01-31\n",
    "   - Includes indicators such as US Retail Sales, ADP Small Establishment Private Employment, ISM Services Business Activity Index, Bank Prime Loan Rate, Treasury Yield Spread, and others\n",
    "   - Also includes BCI, BCIp, and BCIg, which might be related to Business Cycle Indicators\n",
    "\n",
    "Both datasets start around the same time (January 2014) but have different date frequencies (monthly for AllTrainingDataGB1 and possibly daily for GB2_shifted_data). The GB2_shifted_data seems to focus on business loans and related metrics, while the AllTrainingDataGB1 dataset contains a broader range of economic indicators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da765562",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "ok first on the 8_AllTrainingDataGB1.csv dataset, on the Period Column, can you create a script that converts the day number in current yyyy-mm-dd format so the dd changes from whatever it is now to 01. show me the dataframe after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317931e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 8_AllTrainingDataGB1 dataset\n",
    "df_all_training_gb1 = pd.read_csv('8_AllTrainingDataGB1.csv')\n",
    "\n",
    "# Convert the 'Period' column to datetime format\n",
    "df_all_training_gb1['Period'] = pd.to_datetime(df_all_training_gb1['Period'])\n",
    "\n",
    "# Change the day to 01 for all dates in the 'Period' column\n",
    "df_all_training_gb1['Period'] = df_all_training_gb1['Period'].apply(lambda x: x.replace(day=1))\n",
    "\n",
    "# Display the first few rows of the resulting dataframe\n",
    "print(df_all_training_gb1.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d741c509",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "Here are the first 10 rows of the `8_AllTrainingDataGB1.csv` dataset after converting the day number in the 'Period' column to '01':\n",
    "\n",
    "{outputs_dict['05edf7d8']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf08763",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "perfect now left join this dataset on the GB2_shifted_data.csv dataset, join on the DATE and period columns and if the dates dont match exactly use the nearest date so there are no null values after the left join, show me the dataset after please"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9295295e",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "Certainly! I'll perform a left join between the modified 8_AllTrainingDataGB1 dataset and the GB2_shifted_data dataset using the nearest date matching. Here's the code to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027a2d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GB2_shifted_data dataset\n",
    "df_gb2_shifted = pd.read_csv('GB2_shifted_data.csv')\n",
    "\n",
    "# Convert the 'DATE' column in df_gb2_shifted to datetime\n",
    "df_gb2_shifted['DATE'] = pd.to_datetime(df_gb2_shifted['DATE'])\n",
    "\n",
    "# Ensure both dataframes are sorted by date\n",
    "df_all_training_gb1 = df_all_training_gb1.sort_values('Period')\n",
    "df_gb2_shifted = df_gb2_shifted.sort_values('DATE')\n",
    "\n",
    "# Perform the left join with nearest date matching\n",
    "final_merged_df = pd.merge_asof(df_all_training_gb1, df_gb2_shifted, \n",
    "                                left_on='Period', right_on='DATE', \n",
    "                                direction='nearest')\n",
    "\n",
    "# Display the first few rows and info of the resulting dataframe\n",
    "print(final_merged_df.head(10))\n",
    "print(\"\\nDataframe Info:\")\n",
    "print(final_merged_df.info())\n",
    "\n",
    "# Display the column names\n",
    "print(\"\\nColumn Names:\")\n",
    "print(final_merged_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f22fdc2",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "\n",
    "\n",
    "I've performed the left join between the `8_AllTrainingDataGB1.csv` and `GB2_shifted_data.csv` datasets using the nearest date matching. Here's the result:\n",
    "\n",
    "{outputs_dict['7aa8b26a']}\n",
    "\n",
    "{outputs_dict['9d1f8516']}\n",
    "{outputs_dict['b5d1c4ce']}\n",
    "\n",
    "{outputs_dict['f6133abe']}\n",
    "{outputs_dict['9824f3b4']}\n",
    "\n",
    "Key observations:\n",
    "1. The resulting dataframe has 126 entries and 17 columns, combining all the columns from both datasets.\n",
    "2. All columns have 126 non-null values, indicating that there are no missing values after the join.\n",
    "3. The 'Period' column from the 8_AllTrainingDataGB1 dataset and the 'DATE' column from the GB2_shifted_data dataset are both present in the final dataframe.\n",
    "4. The columns from the GB2_shifted_data dataset (BUSLOANS, 3m, 6m, 9m, 12m) have been successfully added to the merged dataframe.\n",
    "5. The dates in the 'Period' and 'DATE' columns match exactly in the sample rows shown, indicating that the nearest date matching worked as expected.\n",
    "\n",
    "This merged dataset now contains a comprehensive set of economic indicators, including retail sales, employment data, business activity indices, interest rates, and business loan information, all aligned by date. This combined dataset should provide a rich source of information for further analysis or modeling of economic trends and relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e0063d",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "perfect now drop the period column, and move the Date column and all columns to the right of it all the way right of this dataframe, show me the dataset after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b114df9",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "Certainly! I'll modify the dataframe as you've requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafc380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Period' column\n",
    "final_merged_df = final_merged_df.drop('Period', axis=1)\n",
    "\n",
    "# Get the list of columns to move\n",
    "columns_to_move = ['DATE', 'BUSLOANS', '3m', '6m', '9m', '12m']\n",
    "\n",
    "# Create a new column order\n",
    "new_order = [col for col in final_merged_df.columns if col not in columns_to_move] + columns_to_move\n",
    "\n",
    "# Reorder the columns\n",
    "final_merged_df = final_merged_df[new_order]\n",
    "\n",
    "# Display the first few rows of the resulting dataframe\n",
    "print(final_merged_df.head(10))\n",
    "\n",
    "# Display info about the dataframe\n",
    "print(\"\\nDataframe Info:\")\n",
    "print(final_merged_df.info())\n",
    "\n",
    "# Display the column names\n",
    "print(\"\\nColumn Names:\")\n",
    "print(final_merged_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de056239",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "Here is the updated dataframe after dropping the 'Period' column and moving the 'DATE' column and all columns to the right of it to the end:\n",
    "\n",
    "{outputs_dict['7e1d3f17']}\n",
    "\n",
    "{outputs_dict['b458b41a']}\n",
    "{outputs_dict['e312898a']}\n",
    "\n",
    "{outputs_dict['f3337c71']}\n",
    "{outputs_dict['6463d3eb']}\n",
    "\n",
    "Key observations:\n",
    "1. The 'Period' column has been successfully dropped.\n",
    "2. The 'DATE' column and the columns 'BUSLOANS', '3m', '6m', '9m', and '12m' have been moved to the rightmost part of the dataframe.\n",
    "3. The dataframe now has 16 columns, with the economic indicators on the left and the business loan data on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda38df0",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "ok almost, can you make the columns in this order 1  DATE                                                                                                     \n",
    "\n",
    "2  BUSLOANS                                                                                                        \n",
    "\n",
    "3  3m                                                                                                              \n",
    "\n",
    "4  6m                                                                                                              \n",
    "\n",
    "5  9m                                                                                                            \n",
    "\n",
    "6  12m   \n",
    "\n",
    "7   US Retail Sales MoM (Percent)                                                                                  \n",
    "\n",
    "8 P Small Establishment Private Employment MoM                                                                 \n",
    "9 USISM Services Business Activity Index                                                                       \n",
    "\n",
    " 10  Bank Prime Loan Rate (Percent)                                                                                  \n",
    "\n",
    " 11  10-2 Year Treasury Yield Spread (Percent)                                                                      \n",
    "\n",
    " 12  US High Yield CCC or Below Option-Adjusted Spread (Percent)                                                    \n",
    "\n",
    " 13 US Net Percentage of Banks Reporting Increased Willingness to Make Consumer Installment Loans        \n",
    "\n",
    " 14  BCI                                                                                                             \n",
    "\n",
    " 15  BCIp                                                                                                            \n",
    "\n",
    " 16  BCIg     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85887f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns as specified\n",
    "new_order = [\n",
    "    'DATE', 'BUSLOANS', '3m', '6m', '9m', '12m',\n",
    "    'US Retail Sales MoM (Percent)', 'ADP Small Establishment Private Employment MoM',\n",
    "    'US ISM Services Business Activity Index', 'Bank Prime Loan Rate (Percent)',\n",
    "    '10-2 Year Treasury Yield Spread (Percent)', 'US High Yield CCC or Below Option-Adjusted Spread (Percent)',\n",
    "    'US Net Percentage of Banks Reporting Increased Willingness to Make Consumer Installment Loans (Percent)',\n",
    "    'BCI', 'BCIp', 'BCIg'\n",
    "]\n",
    "\n",
    "# Reorder the dataframe\n",
    "final_merged_df = final_merged_df[new_order]\n",
    "\n",
    "# Display the first few rows of the resulting dataframe\n",
    "print(final_merged_df.head(10))\n",
    "\n",
    "# Display info about the dataframe\n",
    "print(\"\\nDataframe Info:\")\n",
    "print(final_merged_df.info())\n",
    "\n",
    "# Display the column names\n",
    "print(\"\\nColumn Names:\")\n",
    "print(final_merged_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19835e4f",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "Here is the updated dataframe with the columns reordered as specified:\n",
    "\n",
    "{outputs_dict['f02de0ca']}\n",
    "\n",
    "{outputs_dict['0b138151']}\n",
    "{outputs_dict['b4c422b8']}\n",
    "\n",
    "{outputs_dict['072788f9']}\n",
    "{outputs_dict['05982575']}\n",
    "\n",
    "The columns are now in the desired order, with 'DATE' and the business loan-related columns at the beginning, followed by the economic indicators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022e2f06",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "show me the link to download this as csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1739f5a1",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "To provide you with a download link for the CSV file, I first need to save the dataframe as a CSV file. Let me do that for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4eded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe as a CSV file\n",
    "filename = 'merged_economic_data.csv'\n",
    "final_merged_df.to_csv(filename, index=False)\n",
    "print(f\"File '{filename}' has been saved successfully.\")\n",
    "print(f\"\\nYou can download the file at: https://julius.ai/files?filename={filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b273caed",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "\n",
    "\n",
    "The CSV file has been created and saved successfully. You can download the file using the following link:\n",
    "\n",
    "{outputs_dict['d8854824']}\n",
    "\n",
    "This link will allow you to access and download the CSV file containing the merged and reordered economic data. The file is named 'merged_economic_data.csv' and includes all the columns we've worked with, in the specified order."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}